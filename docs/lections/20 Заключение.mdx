Как сделать надежную ИТ систему:

1. Проектирование
    1. Заложить возможность детектирования сбоев
    1. Заложить мониторинг внутренних исчерпаемых ресурсов
        1. Пулы соединений
        1. Очереди
        1. Воркеры
    1. Заложить мониторинг зависимостей
    1. Найти моменты, где мы можем разменять консистентность на большую доступность
        1. Кеши
    1. Определиться нужно ли скалироваться горизонтально (шардироваться) и выбрать, как это будет работать
        1. Средствами какой-либо БД
        1. Самим приложением
    1. Заложить возможность отключать тяжелый функционал, который предоставляет удобство пользователю
    1. Заложить возможность быстрой починки выключением сбойный участков из балансировки
    1. Поделить на разные сервисы, то что можно быстро и безопасно рестартовать и то, что нельзя
    1. Для нагруженных приложений
        1. Заложить возможность включения дебаг логов для запроса
    1. Если заботит выполнение каждого запроса
        1. Сделать все такие операции идемпотентными (возможно с ключом дедупликации)
        1. Исплользовать "Сагу" с ACID хранилищем для статуса запроса и идемпотентными стадиями
    1. При проектированиии системы учитывать простоту обучения, логичность и вероятные ошибки, из-за того, что инженер что-то не знал или забыл в моменте
1. Надежный код
    1. Выставить таймауты на всех внешних вызовах
    1. Рассказать о своих таймаутах в документации
    1. Понять, где необходимо использовать повторы и реализовать
        1. Не забыть про бюджеты ретраев
    1. Уметь автоматически выключать запросы на внешние причины, чтобы не убивать их нагрузкой, если они не отвечают или отвечают с ошибкой
    1. Убедиться, что правильно пишем ERROR логи (свидетельствуют именно о возникновении нештатной ситуации)
        1. Добиваемся полного отсутствия ошибок в логгах при штатной работе
    1. Уделиться, что возвращаем правильные ошибки
        1. не корректный запрос
        1. наша внутренняя ошибка
    1. Ограничиваем максимальное входящее количество запросов (rate-limit)
1. Устойчивый клиент
    1. Добавляем в клиент возможность отобразить сообщение, когда бек не работает (через примитивный CDN)
    1. Тестируем клиент на то, что он не разваливается при недоступности части API
    1. Закладываем возможности удаленного администрирования клиента (сброс кешей и т.п.)
1. Тестирование
    1. Тестируем адекватность работы, когда сломались зависимости и восстановление
    1. Тестируем работу под нагрузкой, кратно превышающей максимальную рассчетную, и восстановление при возвращении к максимальной рассчетной
1. CI/CD
    1. Делаем более безопасные релизы
        1. Canary и другие методики
1. Мониторинг
    1. Мониторим работу самого функционала
    1. Используем тестирование в продакшен — проберы
    1. Система алертирования звонит на телефон
    1. Дежурные подтверждают прием алерта, в противном случае эскалация на второго дежурного, всю команду, руководство  
1. Детектирование сбоев
    1. Реализованы достаточно надежные способы детектирования сбоев, которые не дают false positive/false negative
    1. Хранится история всех сбоев
1. Команда эксплуатации
    1. Есть специальное обучение для инженеров проекта
    1. Есть документация по продакшену
    1. Есть регулярная встреча с обзором всех текущих проблем продакшена
1. Процессы
    1. Проект можно очень быстро зарелизить
    1. Проект разрабатывается так, что его всегда можно откатить на несколько версий назать (минимум на 3 месяца)
    1. Откат проекта быстрый
    1. Есть план восстановления "с нуля" — DRP
    1. Регулярно проводятся учения
        1. Виртуальные
        1. Реальные
    1. Дежурные реагируют на каждый единичный алерт
    1. После сбоев делается детальный разбор
    1. Задачи после разбора сбоев имеют высокий приоритет и сразу берутся в работу
    1. Разработаны классификации причин и триггеров сбоев, сбои размечаются для сбора статистики
    1. Избегаем хождения на прод и ручных изменений в нем
